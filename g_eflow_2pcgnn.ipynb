{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages\n",
    "import os, time\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model template\n",
    "import m_nn\n",
    "import m_lightning\n",
    "\n",
    "# data\n",
    "import d_mg5_data\n",
    "import awkward as ak\n",
    "\n",
    "# qml\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# pytorch_lightning\n",
    "import lightning as L\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "# pytorch_geometric\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "# wandb\n",
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "wandb.login()\n",
    "\n",
    "# reproducibility\n",
    "L.seed_everything(3020616)\n",
    "\n",
    "# faster calculation on GPU but less precision\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "# directory for saving results\n",
    "root_dir = f\"./result\"\n",
    "if os.path.isdir(root_dir) == False:\n",
    "    os.makedirs(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "cf = {}\n",
    "cf[\"time\"]     = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "cf[\"wandb\"]    = False # <-----------------------------------------------\n",
    "cf[\"project\"]  = \"g_vz_eflow_2pcgnn\"\n",
    "\n",
    "# training configuration\n",
    "cf[\"num_rnd_round\"]     = 3 # <-----------------------------------------------\n",
    "cf[\"num_train_ratio\"]   = 0.8\n",
    "cf[\"num_bin_data\"]      = 1500 # <-----------------------------------------------\n",
    "cf[\"batch_size\"]        = 64\n",
    "cf[\"num_workers\"]       = 0\n",
    "cf[\"max_epochs\"]        = 50 # <-----------------------------------------------\n",
    "cf[\"accelerator\"]       = \"cpu\"\n",
    "cf[\"fast_dev_run\"]      = False\n",
    "cf[\"log_every_n_steps\"] = cf[\"batch_size\"] // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, sig_events, bkg_events, mode=None):\n",
    "        super().__init__()\n",
    "        # jet events\n",
    "        sig_events = self._preprocess(sig_events, 1, mode)\n",
    "        bkg_events = self._preprocess(bkg_events, 0, mode)\n",
    "\n",
    "        # prepare dataset for dataloader\n",
    "        train_idx = int(cf[\"num_train_ratio\"] * len(sig_events))\n",
    "        self.train_dataset = sig_events[:train_idx] + bkg_events[:train_idx]\n",
    "        self.test_dataset  = sig_events[train_idx:] + bkg_events[train_idx:]\n",
    "\n",
    "    def _preprocess(self, events, y, mode):\n",
    "        # \"_\" prefix means that it is a fastjet feature\n",
    "        if mode == \"normalize\":\n",
    "            f1 = np.arctan(events[\"fast_pt\"] / events[\"fatjet_pt\"])\n",
    "            f2 = events[\"fast_delta_eta\"]\n",
    "            f3 = events[\"fast_delta_phi\"]\n",
    "        elif mode == \"\":\n",
    "            f1 = events[\"fast_pt\"]\n",
    "            f2 = events[\"fast_delta_eta\"]\n",
    "            f3 = events[\"fast_delta_phi\"]\n",
    "        arrays = ak.zip([f1, f2, f3])\n",
    "        arrays = arrays.to_list()\n",
    "        events = [torch.tensor(arrays[i], dtype=torch.float32) for i in range(len(arrays))]\n",
    "\n",
    "        # create pytorch_geometric \"Data\" object\n",
    "        data_list = []\n",
    "        for i in range(len(events)):\n",
    "            x = events[i]\n",
    "            edge_index = list(product(range(len(x)), range(len(x))))\n",
    "            edge_index = torch.tensor(edge_index).transpose(0, 1)\n",
    "            x.requires_grad, edge_index.requires_grad = False, False\n",
    "            data_list.append(Data(x=x, edge_index=edge_index, y=y))\n",
    "        return data_list\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=cf[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=cf[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassing(MessagePassing):\n",
    "    def __init__(self, phi):\n",
    "        super().__init__(aggr=\"add\", flow=\"target_to_source\")\n",
    "        self.phi = phi\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propagate(edge_index, x=x)\n",
    "    def message(self, x_i, x_j):\n",
    "        return self.phi(torch.cat((x_i, x_j), dim=-1))\n",
    "    def update(self, aggr_out, x):\n",
    "        return aggr_out\n",
    "\n",
    "class Graph2PCGNN(nn.Module):\n",
    "    def __init__(self, phi, mlp):\n",
    "        super().__init__()\n",
    "        self.gnn = MessagePassing(phi)\n",
    "        self.mlp = mlp\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.gnn(x, edge_index)\n",
    "        x = geom_nn.global_add_pool(x, batch)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classical2PCGNN(Graph2PCGNN):\n",
    "    def __init__(self, gnn_in, gnn_out, gnn_hidden, gnn_layers, mlp_hidden=0, mlp_layers=0):\n",
    "        phi = m_nn.ClassicalMLP(in_channel=gnn_in, out_channel=gnn_out, hidden_channel=gnn_hidden, num_layers=gnn_layers)\n",
    "        mlp = m_nn.ClassicalMLP(in_channel=gnn_out, out_channel=1, hidden_channel=mlp_hidden, num_layers=mlp_layers)\n",
    "        super().__init__(phi, mlp)\n",
    "\n",
    "class QuantumAngle2PCGNN(Graph2PCGNN):\n",
    "    def __init__(self, gnn_qubits, gnn_layers, gnn_reupload, gnn_measurements):\n",
    "        phi = m_nn.QuantumMLP(num_qubits=gnn_qubits, num_layers=gnn_layers, num_reupload=gnn_reupload, measurements=gnn_measurements)\n",
    "        mlp = m_nn.ClassicalMLP(in_channel=len(gnn_measurements), out_channel=1, hidden_channel=0, num_layers=0)\n",
    "        super().__init__(phi, mlp)\n",
    "\n",
    "class QuantumElementwiseAngle2PCGNN(Graph2PCGNN):\n",
    "    def __init__(self, gnn_qubits, gnn_layers, gnn_reupload, gnn_measurements):\n",
    "        phi = nn.Sequential(\n",
    "            m_nn.ElementwiseLinear(in_channel=gnn_qubits),\n",
    "            m_nn.QuantumMLP(num_qubits=gnn_qubits, num_layers=gnn_layers, num_reupload=gnn_reupload, measurements=gnn_measurements),\n",
    "            )\n",
    "        mlp = m_nn.ClassicalMLP(in_channel=len(gnn_measurements), out_channel=1, hidden_channel=0, num_layers=0)\n",
    "        super().__init__(phi, mlp)\n",
    "\n",
    "class QuantumIQP2PCGNN(Graph2PCGNN):\n",
    "    def __init__(self, gnn_qubits, gnn_layers, gnn_reupload, gnn_measurements):\n",
    "        phi = m_nn.QuantumSphericalIQP(num_qubits=gnn_qubits, num_layers=gnn_layers, num_reupload=gnn_reupload, measurements=gnn_measurements)\n",
    "        mlp = m_nn.ClassicalMLP(in_channel=len(gnn_measurements), out_channel=1, hidden_channel=0, num_layers=0)\n",
    "        super().__init__(phi, mlp)\n",
    "\n",
    "class QuantumElementwiseIQP2PCGNN(Graph2PCGNN):\n",
    "    def __init__(self, gnn_qubits, gnn_layers, gnn_reupload, gnn_measurements):\n",
    "        phi = nn.Sequential(\n",
    "            m_nn.ElementwiseLinear(in_channel=gnn_qubits),\n",
    "            m_nn.QuantumSphericalIQP(num_qubits=gnn_qubits, num_layers=gnn_layers, num_reupload=gnn_reupload, measurements=gnn_measurements),\n",
    "            )\n",
    "        mlp = m_nn.ClassicalMLP(in_channel=len(gnn_measurements), out_channel=1, hidden_channel=0, num_layers=0)\n",
    "        super().__init__(phi, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_module, train_info):\n",
    "    # setup wandb logger\n",
    "    if cf[\"wandb\"]:\n",
    "        wandb_info = {}\n",
    "        wandb_info[\"project\"]  = cf[\"project\"]\n",
    "        wandb_info[\"group\"]    = f\"{train_info['sig']}_{train_info['bkg']}\"\n",
    "        wandb_info[\"name\"]     = f\"{train_info['group_rnd']} | {cf['time']}_{train_info['rnd_seed']}\"\n",
    "        wandb_info[\"id\"]       = wandb_info[\"name\"]\n",
    "        wandb_info[\"save_dir\"] = root_dir \n",
    "        wandb_logger = WandbLogger(**wandb_info)\n",
    "        wandb_config = {}\n",
    "        wandb_config.update(cf)\n",
    "        wandb_config.update(train_info)\n",
    "        wandb_config.update(wandb_info)\n",
    "        wandb_logger.experiment.config.update(wandb_config)\n",
    "        wandb_logger.watch(model, log=\"all\")\n",
    "\n",
    "    # start lightning training\n",
    "    logger  = wandb_logger if cf[\"wandb\"] else None\n",
    "    trainer = L.Trainer(\n",
    "        logger            = logger, \n",
    "        accelerator       = cf[\"accelerator\"],\n",
    "        max_epochs        = cf[\"max_epochs\"],\n",
    "        fast_dev_run      = cf[\"fast_dev_run\"],\n",
    "        log_every_n_steps = cf[\"log_every_n_steps\"],\n",
    "        )\n",
    "    litmodel = m_lightning.BinaryLitModel(model, graph=True)\n",
    "    trainer.fit(litmodel, datamodule=data_module)\n",
    "    trainer.test(litmodel, datamodule=data_module)\n",
    "\n",
    "    # finish wandb monitoring\n",
    "    if cf[\"wandb\"]:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = {\"sig\": \"VzToZhToVevebb\", \"bkg\": \"VzToQCD\", \"cut\": (800, 1000), \"bin\":10, \"subjet_radius\":0.1, \"num_bin_data\":cf[\"num_bin_data\"]}\n",
    "sig_fatjet_events = d_mg5_data.FatJetEvents(channel=data_info[\"sig\"], cut_pt=data_info[\"cut\"], subjet_radius=data_info[\"subjet_radius\"])\n",
    "bkg_fatjet_events = d_mg5_data.FatJetEvents(channel=data_info[\"bkg\"], cut_pt=data_info[\"cut\"], subjet_radius=data_info[\"subjet_radius\"])\n",
    "\n",
    "for rnd_seed in range(cf[\"num_rnd_round\"]):\n",
    "    L.seed_everything(rnd_seed)\n",
    "    sig_events  = sig_fatjet_events.generate_uniform_pt_events(bin=data_info[\"bin\"], num_bin_data=data_info[\"num_bin_data\"])\n",
    "    bkg_events  = bkg_fatjet_events.generate_uniform_pt_events(bin=data_info[\"bin\"], num_bin_data=data_info[\"num_bin_data\"])\n",
    "    data_suffix = f\"{data_info['sig']}_{data_info['bkg']}_cut{data_info['cut']}_bin{data_info['bin']}-{data_info['num_bin_data']}_R{data_info['subjet_radius']}\"\n",
    "\n",
    "    # classical\n",
    "    preprocess_mode = \"\"\n",
    "    for go, gh, gl in product([6,18], [(12,1),(12,2),(12,3),(12,4),(48,1),(48,2),(48,3),(48,4)]):\n",
    "        gnn_in, gnn_out, gnn_hidden, gnn_layers = 6, go, gh, gl\n",
    "        model = Classical2PCGNN(gnn_in=gnn_in, gnn_out=gnn_out, gnn_hidden=gnn_hidden, gnn_layers=gnn_layers)\n",
    "        data_module = JetDataModule(sig_events, bkg_events, preprocess_mode)\n",
    "        train_info = {\n",
    "            \"rnd_seed\":rnd_seed, \"model_name\":model.__class__.__name__, \"preprocess_mode\":preprocess_mode,\n",
    "            \"gnn_hidden\":gh, \"gnn_layers\":gl, \"gnn_out\":gnn_out, \"mlp_hidden\":0, \"mlp_layers\":0,\n",
    "            }\n",
    "        train_info[\"group_rnd\"] = f\"{model.__class__.__name__}_{preprocess_mode}_go{gnn_out}_gh{gnn_hidden}_gl{gnn_layers}_mh0_ml0 | {data_suffix}\"\n",
    "        train_info.update(data_info)\n",
    "        train(model, data_module, train_info)\n",
    "\n",
    "    # classical with normalized data\n",
    "    preprocess_mode = \"normalize\"\n",
    "    for go, gh, gl in product([6,18], [(12,1),(12,2),(12,3),(12,4),(48,1),(48,2),(48,3),(48,4)]):\n",
    "        gnn_in, gnn_out, gnn_hidden, gnn_layers = 6, go, gh, gl\n",
    "        model = Classical2PCGNN(gnn_in=gnn_in, gnn_out=gnn_out, gnn_hidden=gnn_hidden, gnn_layers=gnn_layers)\n",
    "        data_module = JetDataModule(sig_events, bkg_events, preprocess_mode)\n",
    "        train_info = {\n",
    "            \"rnd_seed\":rnd_seed, \"model_name\":model.__class__.__name__, \"preprocess_mode\":preprocess_mode,\n",
    "            \"gnn_hidden\":gh, \"gnn_layers\":gl, \"gnn_out\":gnn_out, \"mlp_hidden\":0, \"mlp_layers\":0,\n",
    "            }\n",
    "        train_info[\"group_rnd\"] = f\"{model.__class__.__name__}_{preprocess_mode}_go{gnn_out}_gh{gnn_hidden}_gl{gnn_layers}_mh0_ml0 | {data_suffix}\"\n",
    "        train_info.update(data_info)\n",
    "        train(model, data_module, train_info)\n",
    "\n",
    "    for gnn_measurements in [list(product(range(6), \"Z\")), list(product(range(6), \"XYZ\"))]:\n",
    "        # quantum angle encoding\n",
    "        preprocess_mode = \"normalize\"\n",
    "        for gl, gr in [(1,2), (0,1)]:\n",
    "            gnn_qubits, gnn_layers, gnn_reupload = 6, gl, gr\n",
    "            model = QuantumAngle2PCGNN(gnn_qubits=gnn_qubits, gnn_layers=gnn_layers, gnn_reupload=gnn_reupload, gnn_measurements=gnn_measurements)\n",
    "            data_module = JetDataModule(sig_events, bkg_events, preprocess_mode)\n",
    "            train_info = {\"rnd_seed\":rnd_seed, \"model_name\":model.__class__.__name__, \"preprocess_mode\":preprocess_mode}\n",
    "            train_info[\"group_rnd\"]  = f\"{model.__class__.__name__}_{preprocess_mode}_q{gnn_qubits}_gl{gnn_layers}_gr{gnn_reupload} | {data_suffix}\"\n",
    "            train_info.update(data_info)\n",
    "            train(model, data_module, train_info)\n",
    "\n",
    "        # quantum angle encoding with elementwise linear\n",
    "        preprocess_mode = \"normalize\"\n",
    "        for gl, gr in [(1,2), (0,1)]:\n",
    "            gnn_qubits, gnn_layers, gnn_reupload = 6, gl, gr\n",
    "        model = QuantumElementwiseAngle2PCGNN(gnn_qubits=gnn_qubits, gnn_layers=gnn_layers, gnn_reupload=gnn_reupload, gnn_measurements=gnn_measurements)\n",
    "        data_module = JetDataModule(sig_events, bkg_events, preprocess_mode)\n",
    "        train_info = {\"rnd_seed\":rnd_seed, \"model_name\":model.__class__.__name__, \"preprocess_mode\":preprocess_mode}\n",
    "        train_info[\"group_rnd\"]  = f\"{model.__class__.__name__}_{preprocess_mode}_q{gnn_qubits}_gl{gnn_layers}_gr{gnn_reupload} | {data_suffix}\"\n",
    "        train_info.update(data_info)\n",
    "        train(model, data_module, train_info)\n",
    "\n",
    "        # quantum IQP encoding\n",
    "        preprocess_mode = \"normalize\"\n",
    "        for gl, gr in [(1,2), (0,1)]:\n",
    "            gnn_qubits, gnn_layers, gnn_reupload = 6, gl, gr\n",
    "        model = QuantumIQP2PCGNN(gnn_qubits=gnn_qubits, gnn_layers=gnn_layers, gnn_reupload=gnn_reupload, gnn_measurements=gnn_measurements)\n",
    "        data_module = JetDataModule(sig_events, bkg_events, preprocess_mode)\n",
    "        train_info = {\"rnd_seed\":rnd_seed, \"model_name\":model.__class__.__name__, \"preprocess_mode\":preprocess_mode}\n",
    "        train_info[\"group_rnd\"]  = f\"{model.__class__.__name__}_{preprocess_mode}_q{gnn_qubits}_gl{gnn_layers}_gr{gnn_reupload} | {data_suffix}\"\n",
    "        train_info.update(data_info)\n",
    "        train(model, data_module, train_info)\n",
    "\n",
    "        # quantum IQP encoding with elementwise linear\n",
    "        preprocess_mode = \"normalize\"\n",
    "        for gl, gr in [(1,2), (0,1)]:\n",
    "            gnn_qubits, gnn_layers, gnn_reupload = 6, gl, gr\n",
    "        model = QuantumElementwiseIQP2PCGNN(gnn_qubits=gnn_qubits, gnn_layers=gnn_layers, gnn_reupload=gnn_reupload, gnn_measurements=gnn_measurements)\n",
    "        data_module = JetDataModule(sig_events, bkg_events, preprocess_mode)\n",
    "        train_info = {\"rnd_seed\":rnd_seed, \"model_name\":model.__class__.__name__, \"preprocess_mode\":preprocess_mode}\n",
    "        train_info[\"group_rnd\"]  = f\"{model.__class__.__name__}_{preprocess_mode}_q{gnn_qubits}_gl{gnn_layers}_gr{gnn_reupload} | {data_suffix}\"\n",
    "        train_info.update(data_info)\n",
    "        train(model, data_module, train_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abdd0d95ca50f233d1202cce1ba28eab5ada50f7ec17823ef40ef9b79347f6f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
